{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMwxTFLkO3h3n/oe/ZipTfU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abduljunaid02/LLMs/blob/main/makemore_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "fERscQXJ3gMk"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt # for making figures\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words = open('names.txt', 'r').read().splitlines()\n",
        "words[:8]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NInx5Q5-3jb-",
        "outputId": "b3221153-4ad8-456a-b3a8-3900d8270f06"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['emma', 'olivia', 'ava', 'isabella', 'sophia', 'charlotte', 'mia', 'amelia']"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "chars = sorted(list(set(''.join(words))))\n",
        "stoi = {s:i+1 for i,s in enumerate(chars)}\n",
        "stoi['.'] = 0\n",
        "itos = {i:s for s,i in stoi.items()}\n",
        "print(itos)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2NnwVEhE3yWE",
        "outputId": "25ee60c0-9af4-4949-f190-c5d78267616f"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e', 6: 'f', 7: 'g', 8: 'h', 9: 'i', 10: 'j', 11: 'k', 12: 'l', 13: 'm', 14: 'n', 15: 'o', 16: 'p', 17: 'q', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'v', 23: 'w', 24: 'x', 25: 'y', 26: 'z', 0: '.'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# build the dataset\n",
        "\n",
        "block_size = 3 # context length: how many characters do we take to predict the next one?\n",
        "X, Y = [], []\n",
        "for w in words[:5]:\n",
        "\n",
        "  #print(w)\n",
        "  context = [0] * block_size\n",
        "  for ch in w + '.':\n",
        "    ix = stoi[ch]\n",
        "    X.append(context)\n",
        "    Y.append(ix)\n",
        "    print(''.join(itos[i] for i in context), '--->', itos[ix])\n",
        "    context = context[1:] + [ix] # crop and append\n",
        "\n",
        "X = torch.tensor(X)\n",
        "Y = torch.tensor(Y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "otNf8qeJ3_NH",
        "outputId": "c6066083-7233-4fc5-d354-8fe97bc7597c"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "... ---> e\n",
            "..e ---> m\n",
            ".em ---> m\n",
            "emm ---> a\n",
            "mma ---> .\n",
            "... ---> o\n",
            "..o ---> l\n",
            ".ol ---> i\n",
            "oli ---> v\n",
            "liv ---> i\n",
            "ivi ---> a\n",
            "via ---> .\n",
            "... ---> a\n",
            "..a ---> v\n",
            ".av ---> a\n",
            "ava ---> .\n",
            "... ---> i\n",
            "..i ---> s\n",
            ".is ---> a\n",
            "isa ---> b\n",
            "sab ---> e\n",
            "abe ---> l\n",
            "bel ---> l\n",
            "ell ---> a\n",
            "lla ---> .\n",
            "... ---> s\n",
            "..s ---> o\n",
            ".so ---> p\n",
            "sop ---> h\n",
            "oph ---> i\n",
            "phi ---> a\n",
            "hia ---> .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "  X.shape, Y.shape, X.dtype, Y.dtype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q0fXFkNk5vDw",
        "outputId": "debe8c63-20f4-4b00-9799-58857ad0a251"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([32, 3]), torch.Size([32]), torch.int64, torch.int64)"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "C = torch.randn(27,2)\n",
        "# C is our way of representing the 27 characters in 2 dimensional space.\n",
        "#We will allocate the 27 characters to these 27-2 dimenstional embeddings now"
      ],
      "metadata": {
        "id": "HqeYKPGW8roL"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Direct allocation like C[5] is same as doing one hot encoding for 5 and then multiplying it with 5th entry in C\n",
        "#F.one_hot(torch.tensor(5),num_classes=27).float() @ C\n",
        "\n",
        "C[5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sJEiUkmp82iu",
        "outputId": "74098661-cc94-47db-c591-829b5ff98522"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.8390, 0.6557])"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Accessing works for multiple characters as well\n",
        "\n",
        "C[torch.tensor([5,6,7])]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3jQlZBpy9cE-",
        "outputId": "61b230d6-cc2a-4164-836e-033fd38955ee"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.8390,  0.6557],\n",
              "        [ 0.0779,  0.7256],\n",
              "        [ 0.5928, -0.4863]])"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "C[X].shape\n",
        "\n",
        "#X is our dataset. We can embedd the whole of X in C with this C[X] it returns a (32,3) i.e., of X and a 2 dimension embedding of C\n",
        "#If C were a 5 dimensional embedding it would have been (32,3,5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SOIkit7b9zU-",
        "outputId": "e811274c-d246-48de-934f-a921f4e2f538"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 3, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "emb = C[X]\n",
        "emb.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iNmN3EnX-FwW",
        "outputId": "9bc67019-74c9-4240-e767-9f6c446c51c0"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 3, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Create weights and biases\n",
        "\n",
        "w1 = torch.rand(6, 100) #6 because we are using 3 characters represented in 2 dimensions to predict next character. 3*2 = 6 and 100 neurons\n",
        "b1 = torch.rand(100)"
      ],
      "metadata": {
        "id": "oJFDR3Ph_GI_"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#It is difficult to multiply a (32,3,2) i.e., our embedding vector with our weights that are (6,100). Matrix mul not possible\n",
        "#So convert emb to (32,6)\n",
        "\n",
        "h = torch.tanh(emb.view(-1,6) @ w1 + b1) # using -1 lets torch infer what must come in its place\n",
        "h.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l15z9RJo_z6C",
        "outputId": "22cb6d47-51b4-4ed9-cf33-71f3900614a4"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 100])"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating w2 and b2\n",
        "\n",
        "w2 = torch.randn(100,27) # (100,27) because 100 comes from prev layers and output is 27 characters\n",
        "b2 = torch.rand(27)"
      ],
      "metadata": {
        "id": "X3cePQr2BQ-s"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logits = h @ w2 + b2"
      ],
      "metadata": {
        "id": "LwmrnmNICKMI"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logits.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZYhpYCmKCTAn",
        "outputId": "db5ec107-8e3b-413e-8e83-85afb09593ac"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 27])"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#We have 27 outputs and we make it into the probabilities\n",
        "counts = logits.exp()\n",
        "prob = counts / counts.sum(dim=1, keepdims=True)\n",
        "prob.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5_p7jtESCTlr",
        "outputId": "bbff4fd2-bf77-4798-e28c-872b86c2d7c8"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 27])"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prob.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IrWRuu7iCh_3",
        "outputId": "6e653ae6-2823-40dc-80ca-22aa324af835"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 27])"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prob[torch.arange(32), Y]\n",
        "\n",
        "#This is advanced indexing where we are getting the probabilities of the numbers (in y like 5,12,11,6) from all the 27 probabilities\n",
        "#that prob has"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Ffe__IJDNjo",
        "outputId": "4037b8f7-87cf-4f63-e331-9484aaad5134"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([9.3327e-01, 1.0634e-07, 2.2233e-06, 1.9127e-18, 2.4233e-11, 3.4693e-06,\n",
              "        8.7830e-13, 5.7582e-14, 3.2422e-09, 1.0000e+00, 1.4797e-16, 8.8187e-17,\n",
              "        5.4755e-11, 6.0565e-11, 1.0753e-07, 6.7565e-16, 4.7666e-29, 6.2563e-13,\n",
              "        4.8802e-12, 4.8717e-06, 8.9416e-01, 1.5130e-08, 4.2851e-02, 9.4772e-14,\n",
              "        2.5102e-06, 1.2891e-17, 3.0098e-06, 7.8717e-10, 5.7873e-08, 1.0000e+00,\n",
              "        6.9596e-15, 2.5424e-16])"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Calculating negative loss likelikhood\n",
        "\n",
        "loss = -prob[torch.arange(32), Y].log().mean()\n",
        "loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9KfnRW9YDsFU",
        "outputId": "e9688a52-d7d6-4911-b7e5-8d3e7a3166e9"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(22.1805)"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JW9_g-gDFiWm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}